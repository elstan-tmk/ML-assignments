{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCZYXwtCsL_y"
   },
   "source": [
    "CA02: This is a eMail Spam Classifers that uses Naive Bayes supervised machine learning algorithm. \n",
    "\n",
    "This assignment contains:\n",
    "1. The codes are correctly working with the given parts of the program.\n",
    "2. Codes clearly explained through \"Markdown\" texts and commenting.\n",
    "\n",
    "IMPORTANT NOTE:\n",
    "\n",
    "The path of the data folders 'train-mails' and 'test-mails' must be './train-mails' and './test-mails'. This means you must have your .ipynb file and these folders in the SAME FOLDER in your laptop or Google Drive. The reason for doing this is, this way the peer reviewes and I would be able to run your code from our computers using this exact same relative path, irrespective of our folder hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4p_DvtT7sOIr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Import all necessary libraries.\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jjKF0nIMwz8_"
   },
   "outputs": [],
   "source": [
    "# First create a defination for the root_dir\n",
    "# use os.path.join to join path components into a single complete file path\n",
    "# for every mail in the folder, split the words into a dictionary\n",
    "\n",
    "# list_to_remove is created by taking all the keys of the dictionary\n",
    "\n",
    "def make_Dictionary(root_dir):\n",
    "  all_words = []\n",
    "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)] \n",
    "  for mail in emails:\n",
    "    with open(mail) as m:\n",
    "      for line in m:\n",
    "        words = line.split()\n",
    "        all_words += words\n",
    "  dictionary = Counter(all_words)\n",
    "  list_to_remove = list(dictionary)\n",
    "\n",
    "# Loop through each item in list_to_remove and check if it is an alphabetic string using item.isalpha()\n",
    "# Check if the length of the word is more than 1 character\n",
    "# if either of the conditions is false, the item will be deleted from the dictionary \n",
    "  for item in list_to_remove:\n",
    "    if item.isalpha() == False:\n",
    "      del dictionary[item]\n",
    "    elif len(item) == 1:\n",
    "      del dictionary[item]\n",
    "  dictionary = dictionary.most_common(3000)\n",
    "  return dictionary\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dmVW5xNlyOFc"
   },
   "outputs": [],
   "source": [
    "def extract_features(mail_dir):\n",
    "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
    "  features_matrix = np.zeros((len(files),3000))\n",
    "  train_labels = np.zeros(len(files))\n",
    "  count = 1;\n",
    "  docID = 0;\n",
    "  for fil in files:\n",
    "    with open(fil) as fi:\n",
    "      for i, line in enumerate(fi):\n",
    "        if i ==2:\n",
    "          words = line.split()\n",
    "          for word in words:\n",
    "            wordID = 0\n",
    "            for i, d in enumerate(dictionary):\n",
    "              if d[0] == word:\n",
    "                wordID = i\n",
    "                features_matrix[docID,wordID] = words.count(word)\n",
    "      train_labels[docID] = 0;\n",
    "      filepathTokens = fil.split('/')\n",
    "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
    "      if lastToken.startswith(\"spmsg\"):\n",
    "        train_labels[docID] = 1;\n",
    "        count = count + 1\n",
    "      docID = docID + 1\n",
    "  return features_matrix, train_labels                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zoq-rE7Mx0pp"
   },
   "outputs": [],
   "source": [
    "# Enter the \"path\" of your \"train_mails\" and \"test-mails\" FOLDERS in this cell ...\n",
    "# for example: TRAIN_DIR = '../../train-mails'\n",
    "#              TEST_DIR = '../../test-mails'\n",
    "\n",
    "TRAIN_DIR = \"Data/train-mails\"\n",
    "TEST_DIR =\"Data/test-mails\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127480,
     "status": "ok",
     "timestamp": 1578886833446,
     "user": {
      "displayName": "Arin Brahma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBXGIW7FvUnbm_QmEFGh4rLebuLHNZgc8PuNinU=s64",
      "userId": "05299564422021375910"
     },
     "user_tz": 480
    },
    "id": "134lmhauyQxE",
    "outputId": "83cce6a6-aff5-4e93-ef0a-700606437aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading and processing emails from TRAIN and TEST folders\n"
     ]
    }
   ],
   "source": [
    "dictionary = make_Dictionary(TRAIN_DIR)\n",
    "\n",
    "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
    "features_matrix, labels = extract_features(TRAIN_DIR)\n",
    "test_features_matrix, test_labels = extract_features(TEST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data for modeling: You will need to split the data into training and test sets, and then use the CountVectorizer to convert the email text into a numerical representation that can be used by the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier: You can use the scikit-learn library to train a Multinomial Naive Bayes classifier on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model using Gaussian Naive Bayes algoritm....\n",
      "Training completed\n",
      "testing trained model to predict Test Data labels\n",
      "Completed classification of the Test Data\n",
      "... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
      "Accuracy: 0.9653846153846154\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf = GaussianNB()\n",
    "print(\"Training Model using Gaussian Naive Bayes algoritm....\")\n",
    "clf.fit(features_matrix, labels)\n",
    "print(\"Training completed\")\n",
    "print(\"testing trained model to predict Test Data labels\")\n",
    "y_pred = clf.predict(test_features_matrix)\n",
    "print(\"Completed classification of the Test Data\")\n",
    "print(\"... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
    "accuracy = accuracy_score(test_labels, y_pred)\n",
    "print(f\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the classifier: You can use the trained classifier to make predictions on the test data, and then evaluate the accuracy of the classifier using the accuracy_score function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M5_mPrvN586A"
   },
   "source": [
    "======================= END OF PROGRAM ========================="
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOaSi3qlFUlqTup/1esXCKD",
   "collapsed_sections": [],
   "name": "naive_bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "bf3153f29b6a954d62afc0116bc41f9efdca119a3bb29d09d72b104f272df27d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
